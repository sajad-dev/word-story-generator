# Word Story Generator

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.x-3776AB.svg?style=flat&logo=python" alt="Python Version">
  <img src="https://img.shields.io/badge/Jupyter-Notebook-F37626.svg?style=flat&logo=jupyter" alt="Jupyter Notebook">
  <img src="https://img.shields.io/badge/TensorFlow-PyTorch-FF6F00.svg?style=flat&logo=tensorflow" alt="Deep Learning">
  <img src="https://img.shields.io/badge/AI-Story%20Generation-00D4AA.svg?style=flat&logo=openai" alt="AI Story Generation">
  <img src="https://img.shields.io/badge/License-MIT-green.svg?style=flat" alt="License">
  <img src="https://img.shields.io/badge/Version-1.0.0-blue.svg?style=flat" alt="Version">
  <img src="https://img.shields.io/badge/Status-Stable-brightgreen.svg?style=flat" alt="Status">
</p>

This project uses deep learning techniques to generate word stories based on a given dataset. It is implemented in Python and uses Jupyter Notebook for training and testing the model. The model is built using neural networks to predict the next word in a sequence, ultimately generating coherent stories.

## ğŸ¯ Model Performance

| Metric        | Score |
|---------------|-------|
| Epoch         | 200   |
| Loss          | 0.04  |
| Val Loss      | 0.3   |
| Accuracy      | 0.994 |
| Val Accuracy  | 0.98  |

## ğŸ“‹ Requirements

To run the project, you need the following:

- Python 3.x
- Jupyter Notebook
- TensorFlow or PyTorch (depending on your preference)
- Numpy
- Pandas
- Matplotlib for visualizations

## ğŸš€ Installation and Setup

Follow these steps to set up the project:

**1. Clone the repository:**
```bash
git clone https://github.com/your-username/word-story-generator.git
```

**2. Navigate to the project directory:**
```bash
cd word-story-generator
```

**3. Install the necessary dependencies:**
```bash
pip install -r requirements.txt
```

**4. Open the Jupyter Notebook:**
```bash
jupyter notebook
```

## ğŸ“Š How it works

1. **Dataset**: The dataset used for training contains text data in the form of stories or paragraphs.

2. **Model Training**: The model is trained using a neural network to predict the next word based on the input sequence.

3. **Story Generation**: After training, the model generates new word stories by iteratively predicting the next word.

## ğŸ§‘â€ğŸ’» Author

**Mohammad Sajad Poorajam** ğŸ‘¨â€ğŸ’»ğŸš€
