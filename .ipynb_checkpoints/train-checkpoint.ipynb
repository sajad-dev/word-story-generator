{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3db1a166-677e-4062-8b89-e008314e9501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras \n",
    "import hazm\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362b1ac-4f5d-426b-8c84-ebf4d2306ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O pos_tagger.model \"https://drive.usercontent.google.com/u/0/uc?id=1Q3JK4NVUC2t5QT63aDiVrCRBV225E_B3&export=download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41fca7d9-b96d-4d94-811a-104f26b3575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = []\n",
    "count={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba9844-b78f-4c2a-a7e4-6e68ea3ada08",
   "metadata": {},
   "source": [
    "# **Text Preprocessing and Data Preparation for Machine Learning Models Using Hazm**\n",
    "\n",
    "This code preprocesses Persian textual data and prepares it for machine learning models, such as RNNs or LSTMs.\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Overview**\n",
    "\n",
    "The following steps are performed:\n",
    "\n",
    "1. **Reading Data from a File**  \n",
    "   The text is read from `data.txt` and stored in a variable.\n",
    "\n",
    "2. **Removing Empty Lines**  \n",
    "   Extra empty lines (`\\n\\n`) are removed from the text.\n",
    "\n",
    "3. **Stemming and Lemmatization**  \n",
    "   The `hazm` library is used to normalize the text:\n",
    "   - **Stemming:** Reduces words to their root form.\n",
    "   - **Lemmatization:** Converts words to their base dictionary form.\n",
    "\n",
    "4. **Tokenization and POS Tagging**  \n",
    "   - The text is tokenized into individual words.  \n",
    "   - POS (Part-of-Speech) tagging is applied using the `pos_tagger.model`.  \n",
    "   - Each word is tagged in the format `[word-POS_tag]`.\n",
    "\n",
    "5. **Creating Unique Tokens and Counting Frequencies**  \n",
    "   - A list of unique tokens is created.  \n",
    "   - The frequency of each token in the text is calculated.\n",
    "\n",
    "6. **Token-to-Index Conversion**  \n",
    "   Tokens are replaced with their respective indices to prepare numerical input for models.\n",
    "\n",
    "7. **Data Preparation for Model Training**  \n",
    "   A sliding window of size 10 is applied:\n",
    "   - `X_train` contains sequences of 10 consecutive words (as indices).  \n",
    "   - `Y_train` contains the next word following each sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e177b-8b7b-4e36-bb7e-bb1bf9bdff3d",
   "metadata": {},
   "source": [
    "### Reading Data from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca3008e4-739c-40b7-8bce-4baa65eb5a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data.txt\",\"r\") as file:\n",
    "    contact =file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b637ab-152b-48d2-97f6-b43d723241eb",
   "metadata": {},
   "source": [
    "### Removing Empty Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5746b8ba-3538-4d06-9cc4-6e140e8c49ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contact = contact.replace(\"\\n\\n\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a641b7-15bb-4aac-a155-89cfe7450fc9",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5931c2c3-d49a-44fc-a941-4006f5683440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemmer = hazm.Stemmer()\n",
    "contact=stemmer.stem(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40bb7d31-88cc-41b4-b459-c1cad95a944c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = hazm.Lemmatizer()\n",
    "contact=lemmatizer.lemmatize(contact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a8d93-f127-47f7-baca-92e3d79a8728",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenization and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43e9d649-a680-402b-a577-02ea70f3021d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge (arr) :\n",
    "    arr1=[]\n",
    "    for v in arr:\n",
    "        arr1.append(f\"[{v[0]}-{v[1]}]\")\n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c48df80f-5878-4c30-a4dd-37c39753c21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contact=hazm.word_tokenize(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a415831b-b880-4205-8b5b-402553c3e44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spacy_posTagger = hazm.POSTagger(model='pos_tagger.model')\n",
    "contact=merge(spacy_posTagger.tag(tokens = contact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23cf69e2-1ccc-41dd-8bb7-bf845b592ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,value in enumerate(contact):\n",
    "    if not value in token:\n",
    "        token.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29346a8-7fe1-4ca7-bba2-8e79dd07d14a",
   "metadata": {},
   "source": [
    "### Creating Unique Tokens and Counting Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0b3ee60-cd0e-494d-ac53-81d063785a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,value in enumerate(token):\n",
    "    count[value]=contact.count(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d61292-7146-45ea-91be-56714f55b82b",
   "metadata": {},
   "source": [
    "### Token-to-Index Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "246ed037-66c5-4aa3-9aca-6b5f49004e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,value in enumerate(contact):\n",
    "    contact[index] = token.index(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2fe40b-701f-4213-bda8-6b543ea2275c",
   "metadata": {},
   "source": [
    "### Data Preparation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f04de93-ec14-4638-897b-d4e9d28ae735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26930094-9415-4619-8898-a4835da92099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index,value in enumerate(contact):\n",
    "    if len(contact)-10 > index:\n",
    "        X_train.append(contact[index:index+10])\n",
    "        Y_train.append(contact[index+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6439a214-99e2-4df8-98d6-dd158d156449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc8881-3cc5-4b78-9aa1-43537e4b205d",
   "metadata": {},
   "source": [
    "# **Training an LSTM Model for Text Prediction**\n",
    "\n",
    "This section defines and trains an LSTM-based model using Keras for predicting the next word in a sequence of Persian text.\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Overview**\n",
    "\n",
    "The following steps are performed:\n",
    "\n",
    "1. **Model Architecture:**\n",
    "   - An **Embedding layer** maps the tokenized words to dense vector representations.\n",
    "   - An **LSTM layer** processes the sequences and learns long-term dependencies.\n",
    "   - A **Dense layer** with a softmax activation predicts the next word.\n",
    "\n",
    "2. **Model Compilation:**\n",
    "   - **Optimizer:** Adam optimizer for efficient training.  \n",
    "   - **Loss Function:** `sparse_categorical_crossentropy` is used for multi-class classification.  \n",
    "   - **Metrics:** Accuracy is monitored.\n",
    "\n",
    "3. **Callbacks for Training:**\n",
    "   - **ModelCheckpoint:** Saves the best model based on `val_loss` and `loss`.\n",
    "   -   \n",
    "4. **Training:**\n",
    "   - The model is trained using `X_train` and `Y_train` with a validation split of 1%.  \n",
    "   - The model runs for 1000 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4308afe-acfb-4770-b8d6-9ae6481de079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(token) + 1 \n",
    "maxlen=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a63921f-a2ab-407d-adaa-96b11c2aedc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b82f2-54f0-4078-bc1f-14d8d6b4cf4a",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4332b3f2-6ff7-42df-bad7-8871a6dfeb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(keras.layers.Embedding(vocab_size, 7000, input_length=10))\n",
    "model.add(keras.layers.LSTM(1024))  \n",
    "model.add(keras.layers.Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477e516-e40f-4071-8784-90c499e85fea",
   "metadata": {},
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16950c68-ccda-4526-b852-5f027f5907c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb562251-28bd-482e-a4dd-3f3354792e9b",
   "metadata": {},
   "source": [
    "### Callbacks for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b06d7a7b-1d54-47ca-8d78-6543cba39407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_val_loss = ModelCheckpoint('token_generator_best_val_loss.keras', save_best_only=True,monitor=\"val_loss\")\n",
    "checkpoint_loss = ModelCheckpoint('token_generator_best_loss.keras', save_best_only=True,monitor=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea055731-d5da-4f87-9ca3-df422cfd752e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532aba2-7a0d-4be0-8bcc-49c34c627039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=1000,validation_split=0.01,callbacks=[checkpoint_val_loss,checkpoint_loss])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
